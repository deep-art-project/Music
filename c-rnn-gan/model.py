import torch.nn as nn
import torch.autograd as autograd
import torch.nn.functional as F
import torch


class CRnnGan(nn.Module):

    def __init__(self):
        super(CRnnGan, self).__init__()

        pass

    def forward(self, **kwargs):
        raise NotImplementedError

    def init_hidden(self, num_layer, batch_size, directions=1):
        '''
        Initialize hidden info = [hidden state, cell state].
        Hidden state [num_layers, batch_size, hidden_dim].
        Cell state [num_layers, batch_size, hidden_dim].
        :return:
        '''
        return autograd.Variable(torch.zeros(num_layer*directions, batch_size, self.num_hidden)), \
               autograd.Variable(torch.zeros(num_layer*directions, batch_size, self.num_hidden))


class Generator(CRnnGan):

    def __init__(self,
                 song_len,
                 batch_size,
                 num_feature,
                 rand_feature_dim,
                 num_hidden=350,
                 keep_prob=0.5):
        '''
        Generator of C-R-GAN.
        Get a midi sequence which is similar to a real music.
        :var input_dim: Input song dimension = [song_len, batch_size, num_feature].
                          A random input.
        :param song_len:
        :param batch_size:
        :param num_feature:
        :param rand_feature_dim: Num feature of rand_inputs
        :param num_hidden: Hidden units of Generator. Default 350.
        :param keep_prob: The probability of keeping weights in the dropout layer. Default 0.5.
        :var num_layer: Number of LSTM layers. Default 2.
        '''
        super(Generator, self).__init__()
        self.song_len, self.batch_size, self.num_feature = song_len, batch_size, num_feature
        self.rand_feature_dim = rand_feature_dim

        '''Song Generator'''
        # 1. Linear Part
        self.fc1 = nn.Linear(self.rand_feature_dim*2, num_hidden)

        # 2. LSTM Part
        self.lstm_g1 = nn.LSTMCell(num_hidden, num_hidden)
        self.ht1, self.ct1 = self.init_hidden(1, self.batch_size, directions=1)
        self.lstm_g2 = nn.LSTMCell(num_hidden, num_hidden)
        self.ht2, self.ct2 = self.init_hidden(1, self.batch_size, directions=1)

        # 3. Linera Part
        self.fc2 = nn.Linear(self.lstm_g.out_features, self.num_feature)

        '''Meta Generator'''


    def forward(self, inputs=None, isPretraining=False):
        '''
        Generator network.
        :param inputs: A song = [song_len, batch_size, num_song_feature]. Default None.
                       It must given when isPretraining == True.
        :param isPretraining: Whether to pretraining.
                              If isPretraining==True, output_t is generated by inputs_{t-1}, and inputs must given
                              if isPretraining==False, output_t is generated by output_{t-1}.

        :return:
        :variable rand_inputs: Input random song with dimension = [song_len, batch_size, num_rand_feature]
        1st layer: Two LSTM. Out -> [song_len, batch_size, num_hidden]
        2st layer: Linear. Out -> [batch_size, num_song_feature]
        '''

        # initialization
        outputs = torch.Tensor(self.song_len, self.batch_size, self.num_feature)
        rand_inputs = torch.Tensor(self.song_len, self.batch_size, self.rand_feature_dim).uniform_(0, 1)
        generated_point = torch.Tensor(self.batch_size, self.rand_feature_dim).uniform_(0, 1)

        # Get a song
        for i in range(self.song_len):
            x = rand_inputs[i]
            x = torch.cat((x, generated_point), 1)
            x = nn.ReLU(self.fc1(x))
            self.ht1, self.ct1 = self.lstm_g1(x, (self.ht1, self.ct1))
            self.ht2, self.ct2 = self.lstm_g2(self.ht1, (self.ht2, self.ct2))
            out = self.fc2(self.ht2)
            generated_point = inputs[i] if isPretraining else out
            outputs[i] = out

        return outputs


class Discriminator(CRnnGan):

    def __init__(self,
                 batch_size,
                 num_feature,
                 num_hidden,
                 num_lstm_d,
                 keep_prob,
                 is_bidrectional):
        '''
        Discriminator of C-R-GAN to distinguish real song from fake one.
        :var input_dim: Input song dimension = [song_len, batch_size, num_song_feature]
        :param batch_size:
        :param num_feature:
        :param num_hidden: Hidden units of Discriminator. Default 350.
        :param num_lstm_d: Number of LSTM layers which is bidirectional. Default 2.
        :param keep_prob: The probability of keeping weights in the dropout layer. Default 0.5.
        :param is_bidrectional: Whether use bidirectional lstm in D.
        '''
        super(Discriminator, self).__init__()

        # 1. LSTM Part
        self.lstm_d = nn.LSTM(input_size=num_feature, hidden_size=num_hidden,
                           num_layers=num_lstm_d, dropout=keep_prob, bidirectional=is_bidrectional)
        self.hidden = self.init_hidden(num_lstm_d, batch_size, directions=2 if is_bidrectional else 1)

        # 2. Linear Part
        self.fc = nn.Linear(self.lstm_d.out_features, 1)

    def forward(self, inputs):
        out, self.hidden = self.lstm_d(inputs, self.hidden)
        # TODO: view
        decision = nn.Softmax(self.fc(out))
        return decision, out


